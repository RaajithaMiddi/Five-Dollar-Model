{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports",
   "id": "b26629fc2d7ca83c"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-24T07:08:20.093624Z",
     "start_time": "2024-07-24T07:08:20.091068Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import time \n",
    "import re\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "import openai\n",
    "import tiktoken"
   ],
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T02:24:10.035806Z",
     "start_time": "2024-07-24T02:24:10.034477Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "83fd8dbdab0162b",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T02:24:10.050957Z",
     "start_time": "2024-07-24T02:24:10.036420Z"
    }
   },
   "cell_type": "code",
   "source": "data = np.load('datasets/emoji_apple_style.npy', allow_pickle=True).item()",
   "id": "c4ec8847364209fe",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T02:24:10.055458Z",
     "start_time": "2024-07-24T02:24:10.052213Z"
    }
   },
   "cell_type": "code",
   "source": "data.keys()",
   "id": "5074269279a19c18",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['images', 'labels', 'embeddings', 'color_palette'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T03:06:52.079190Z",
     "start_time": "2024-07-24T03:06:52.071104Z"
    }
   },
   "cell_type": "code",
   "source": "data = list(data)",
   "id": "93671e515d0eba68",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T03:06:54.645477Z",
     "start_time": "2024-07-24T03:06:53.357770Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# sentence embedding model\n",
    "# https://huggingface.co/sentence-transformers/multi-qa-MiniLM-L6-cos-v1\n",
    "\n",
    "# limit of 512 word pieces, trained on length of 250 word pieces and might not work for longer texts\n",
    "\n",
    "uri_name = \"sentence-transformers/multi-qa-MiniLM-L6-cos-v1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(uri_name)\n",
    "model = AutoModel.from_pretrained(uri_name)"
   ],
   "id": "7cc3146ffeee98c2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/henrymei/anaconda3/envs/five-dollar-model/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Feature Generation",
   "id": "661de64a2bb5a020"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create embeddings",
   "id": "1c3664de4510a99d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T07:24:27.003985Z",
     "start_time": "2024-07-24T07:24:27.000645Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Mean Pooling - Take average of all tokens\n",
    "# see: https://huggingface.co/sentence-transformers/multi-qa-MiniLM-L6-cos-v1#pytorch-usage-huggingface-transformers\n",
    "def _mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output.last_hidden_state\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)"
   ],
   "id": "7581be0f8c9081c2",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T07:24:28.241262Z",
     "start_time": "2024-07-24T07:24:28.237684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _tokenize(texts, tokenizer, max_length):\n",
    "    \"\"\"\n",
    "    Generate token for input text. \n",
    "    :param texts: a list of input sentences or texts to be processed\n",
    "    :param tokenizer: a Hugging Face tokenizer instance\n",
    "    :param max_length: an optional parameter for padding/truncation of text strings\n",
    "    :return: encoded inputs \n",
    "    \"\"\"\n",
    "    \n",
    "    padding = True if max_length == 0 else 'max_length'\n",
    "    \n",
    "    # __call__ the tokenizer \n",
    "    return tokenizer(\n",
    "        texts, \n",
    "        padding=padding,\n",
    "        truncation=True,\n",
    "        max_length=max_length,  # if left unset, uses model default \n",
    "        return_tensors='pt'  # return as torch tensors \n",
    "    )    "
   ],
   "id": "b6dcec421a9b6349",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T07:24:30.151715Z",
     "start_time": "2024-07-24T07:24:30.147790Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _embed(encoded_input, model):\n",
    "    \"\"\"\n",
    "    Take tokenized values and generate embeddings\n",
    "    :param encoded_input: encoded inputs generated by tokenizer \n",
    "    :param model: a Hugging Face model instance\n",
    "    :return: embedding vector\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():  # only need forward pass here\n",
    "        embeddings_words = model(**encoded_input, return_dict=True)\n",
    "\n",
    "    # Perform mean pooling\n",
    "    # The attention mask ensures that padding tokens do not contribute to the averaged embedding.\n",
    "    # purpose is to take variable length sequences and output fixed length ones \n",
    "    embeddings_sentence = _mean_pooling(embeddings_words, encoded_input['attention_mask'])\n",
    "\n",
    "    # Normalize embeddings -- L2 = 1\n",
    "    embeddings_sentence = F.normalize(embeddings_sentence, p=2, dim=1)\n",
    "    \n",
    "    return embeddings_sentence, embeddings_words"
   ],
   "id": "c10954079b5c2f17",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T07:24:34.432454Z",
     "start_time": "2024-07-24T07:24:34.428601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_sent_word_embeddings(labels, model, tokenizer, max_length=None):\n",
    "    \"\"\"\n",
    "    Generate sentence embedding for input texts\n",
    "    :param model: Hugging Face model instance\n",
    "    :param tokenizer: Hugging Face tokenizer instance\n",
    "    :param labels: input labels from our training data \n",
    "    :param max_length: maximum length for padding/truncation fo input stirngs\n",
    "    :return: both mean-pooled sentence embedding and masked word embeddings \n",
    "    \"\"\"\n",
    "    encoded = _tokenize(labels, tokenizer, max_length)\n",
    "    embeddings_sentences, embeddings_words = _embed(encoded, model)\n",
    "\n",
    "    embeddings_words = embeddings_words['last_hidden_state'].detach().cpu().numpy()\n",
    "    embeddings_sentences = embeddings_sentences.detach().cpu().numpy()\n",
    "\n",
    "    return embeddings_sentences, embeddings_words"
   ],
   "id": "410102564bf0fe31",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## GPT Augmentation",
   "id": "dd20fa73c358de96"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T03:07:03.954414Z",
     "start_time": "2024-07-24T03:07:03.951700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "openai.organization = ''\n",
    "openai.api_key='' # enter open ai API key here :)"
   ],
   "id": "60ff3a1bb4a858e9",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T06:34:41.909931Z",
     "start_time": "2024-07-24T06:34:41.905588Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _compute_tokens(payload, encoding):\n",
    "    \"\"\"\n",
    "    Estimate the number of tokens required in the request. \n",
    "    See: https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken\n",
    "    \n",
    "    :param payload: an array of dicts or an array of strings \n",
    "    :param encoding: a tiktoken encoder instance \n",
    "    :param model: the name of the openAI model used \n",
    "    :return: a count of tokens \n",
    "    \"\"\"\n",
    "    num_tokens = 0\n",
    "    for message in payload:\n",
    "        num_tokens += 4  # every message follows <im_start>{role/name}\\n{content}<im_end>\\n\n",
    "        \n",
    "        # if we pass a wellformed payload \n",
    "        if type(message) == dict:\n",
    "            for key, value in message.items():\n",
    "                num_tokens += len(encoding.encode(value))\n",
    "                \n",
    "                # if there's a name, the role is not processed and so doesn't count to api usage\n",
    "                if key == \"name\":  \n",
    "                    num_tokens += -1 \n",
    "        # if we pass a list of labels \n",
    "        else:\n",
    "            num_tokens += len(encoding.encode(message))\n",
    "    \n",
    "    # pad the estimate with the structure of response; note: does not include actual response\n",
    "    # every reply is primed with <im_start>assistant     \n",
    "    num_tokens += 2  \n",
    "    \n",
    "    return num_tokens"
   ],
   "id": "5dc83887bb3a795d",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T06:34:45.521496Z",
     "start_time": "2024-07-24T06:34:45.518858Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _create_payload(labels):\n",
    "    prompt = \"\"\"Take each string in the list provided, and write an alternate label for each one. These strings describe an image of a pixel video game map. These alternate labels should describe the same image as the original label, but use different words and a different sentence structure. Use simple or common words when writing the alternate labels. Assume you have the vocabulary of a 10 year old. Your output should have the same number of strings as the input list.\"\"\"\n",
    "\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant with excellent attention to detail. You only output python lists of strings according to the instructions you are given. Output the list on a single line, without any newlines. Make sure every list is closed properly\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{prompt} Here is the list of labels: {labels}\"},            \n",
    "    ]"
   ],
   "id": "dd2c6783f39a1000",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T06:35:38.476811Z",
     "start_time": "2024-07-24T06:35:38.474071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _call_gpt(messages, model):\n",
    "    return openai.ChatCompletion.create(model=model, messages=messages)"
   ],
   "id": "1da52371195fb2c2",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T06:40:30.360086Z",
     "start_time": "2024-07-24T06:40:30.354896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# segment the data into sublists to not exceed api limits\n",
    "\n",
    "# tiktoken is a fast open-source tokenizer by OpenAI.\n",
    "\n",
    "# Given a text string (e.g., \"tiktoken is great!\") and an encoding (e.g., \"cl100k_base\"), a tokenizer can split the text string into a list of tokens (e.g., [\"t\", \"ik\", \"token\", \" is\", \" great\", \"!\"]).\n",
    "# \n",
    "# Splitting text strings into tokens is useful because GPT models see text in the form of tokens. Knowing how many tokens are in a text string can tell you (a) whether the string is too long for a text model to process and (b) how much an OpenAI API call costs (as usage is priced by token).\n",
    "def _chunk_labels(labels, encoding, threshold):\n",
    "    \"\"\"\n",
    "    \n",
    "    :param labels: feature inputs as a list of strings\n",
    "    :param encoding: a tiktoken encoder instance\n",
    "    :param threshold: a maximum token size to chunk the inputs into \n",
    "    :return: \n",
    "    \"\"\"\n",
    "\n",
    "    current_chunk, chunks = [], []\n",
    "    count_tokens = 0\n",
    "    label_tokens = _compute_tokens(labels, encoding)\n",
    "    \n",
    "    # step throw all labels \n",
    "    for label, tokens in zip(labels, label_tokens):\n",
    "       \n",
    "        # append labels to the current chunk and update our count\n",
    "        current_chunk.append(label)\n",
    "        count_tokens += tokens \n",
    "        \n",
    "        # if the array exceeds the token threshold then.... \n",
    "        if count_tokens + 2 > threshold:\n",
    "            \n",
    "            # remove the last label \n",
    "            hold = current_chunk.pop()\n",
    "            \n",
    "            # complain if the label itself is so big that it's as big as the threshold\n",
    "            if tokens > threshold:\n",
    "                raise Exception(f\"Element at position *{i}*, *'{[hold]}'* is too big: *{size} tokens* for this threshold: *{threshold} tokens*\")\n",
    "            \n",
    "            # since we removed the offending label, the current chunk should be the right size\n",
    "            chunks.append(current_chunk)\n",
    "            \n",
    "            # start a new arr with the one we popped out and reset our counter\n",
    "            current_chunk = [hold] \n",
    "            count_tokens = 0\n",
    "            \n",
    "    # add the final set of labels \n",
    "    chunks.append(current_chunk)\n",
    "    \n",
    "    return chunks"
   ],
   "id": "dfafabdb44cf5dd7",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T07:15:19.027123Z",
     "start_time": "2024-07-24T07:15:19.023116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _process_result(result):\n",
    "    \"\"\"\n",
    "    Filter out patterns that look like [' and '] \n",
    "    TODO: why don't we just look at those patterns directly instead of regex? \n",
    "    :param result: raw openAI API response \n",
    "    :return: processed answers \n",
    "    \"\"\"\n",
    "    answer = result.choices[0]['message']['content']                \n",
    "    apostrophe_pattern = r\"(?<=\\w)'(?=[^,\\]])|'(?=\\w+?'\\s)\"\n",
    "    answer = re.sub(apostrophe_pattern, '', answer)\n",
    "    \n",
    "    idx_open = answer.find(\"[\")\n",
    "    idx_close = answer.find(']') + 1 # +1 since indexing ignores current spot \n",
    "    \n",
    "    return answer[idx_open:idx_close]"
   ],
   "id": "9a5c6fc0cc4d534a",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T07:21:03.368752Z",
     "start_time": "2024-07-24T07:21:03.361782Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_gpt_alt_labels(labels, model='gpt-4o-mini', num_retries=3, debug=True):\n",
    "    \"\"\"\n",
    "    Call GPT to generate alternate labels. \n",
    "    :param labels: list of human-annotated labels \n",
    "    :param num_retries: how many times do we try again? \n",
    "    :return: (a list of alternate labels, api call response status)\n",
    "    \"\"\"\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    # it's probably clk100k_base (can pass to get_encoding()), but let's not assume\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    prompt_size = _compute_tokens(_create_payload([]), encoding)\n",
    "    \n",
    "    # chunk the prompt to the right size; if we pass in everything, it's gonna timeout/fail\n",
    "    threshold = 4000 - prompt_size \n",
    "    chunks = _chunk_labels(labels, encoding, threshold=threshold)\n",
    "\n",
    "    \n",
    "    if debug:\n",
    "        print(f'Prompt size: {prompt_size}')\n",
    "        print(f\"split time = {time.time() - start}\")\n",
    "        print(\"Number of loops: \", len(chunks))\n",
    "        \n",
    "    labels, ans_arr = [], []\n",
    "    \n",
    "\n",
    "    for i, labels in enumerate(chunks):\n",
    "        tries = 0\n",
    "        success = False\n",
    "        start = time.time()\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"Loop {i} running through array of size {len(labels)}\")\n",
    "\n",
    "        while not success and tries < num_retries:\n",
    "            result = _call_gpt(labels, model)\n",
    "            alt_labels = _process_result(result)\n",
    "\n",
    "            n_labels = len(labels)\n",
    "            n_alts = len(alt_labels)\n",
    "            \n",
    "            if n_labels == n_alts:\n",
    "                success = True\n",
    "            else:\n",
    "                tries += 1\n",
    "                \n",
    "                print(f'FAILED. {n_labels} labels but {n_alts} alts!')\n",
    "                print(f'attempting retry # {tries}')\n",
    "                \n",
    "        if success:\n",
    "            labels += alt_labels\n",
    "        else:\n",
    "            print(f\"failed completely after {num_retries} retries.\")\n",
    "            return\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"api call time = {time.time() - start}\")\n",
    "\n",
    "    return alt_labels"
   ],
   "id": "8f815b6d9c3c7137",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d64b101255517b28"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# encode() also tokenizes if this is a sentence transformer but we don't use sentence-transformer\n",
    "# # we only use transformer so doublecheck if this owrks the way we intent it to \n",
    "\n",
    "# but also, maybe we already use tiktoken to tokenize for gpt3/4.\n",
    "# but waht about the output of gpt3/4? we still need to tokenize that appropriately \n",
    "\n",
    "def embed_labels(labels, embedding_model):\n",
    "    labels = np.array(labels)\n",
    "    embeddings = embedding_model.encode(labels)\n",
    "    return embeddings"
   ],
   "id": "a09361c542efba09"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# TODO: eliminate this thing since we should reuse previous embedding code \n",
    "def gpt_augmentation(ann_ids, maps, labels, embeddings, authors, embedding_model):\n",
    "    augmented_annids, augmented_maps, augmented_labels, augmented_embeddings, augmented_authors = [], [], [], [], []\n",
    "    alt_labels, _ = get_gpt_alt_labels(labels)\n",
    "    print(len(alt_labels))\n",
    "    print(len(labels))\n",
    "\n",
    "    assert len(alt_labels) == len(labels)\n",
    "\n",
    "    alt_label_embeddings = embed_labels(alt_labels, embedding_model)\n",
    "\n",
    "    for i, (alt_label, alt_label_embedding) in enumerate(zip(alt_labels, alt_label_embeddings)):\n",
    "        # append original ann_id twice\n",
    "        augmented_annids.append(ann_ids[i])\n",
    "        augmented_annids.append(ann_ids[i])\n",
    "\n",
    "        augmented_authors.append(authors[i])\n",
    "        augmented_authors.append(authors[i])\n",
    "\n",
    "        # append original map twice\n",
    "        augmented_maps.append(maps[i])\n",
    "        augmented_maps.append(maps[i])\n",
    "\n",
    "        # append the original label and the alt label\n",
    "        augmented_labels.append(labels[i])\n",
    "        augmented_labels.append(alt_label)\n",
    "\n",
    "        # append the original embedding and the alt labels embedding\n",
    "        augmented_embeddings.append(embeddings[i])\n",
    "        augmented_embeddings.append(alt_label_embedding)\n",
    "\n",
    "\n",
    "\n",
    "    return augmented_annids, augmented_maps, augmented_labels, augmented_embeddings, augmented_authors"
   ],
   "id": "157c4ed1263d78be"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "58c6ef7d9a106c7b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Tokenize Input",
   "id": "46d306163e0aa31c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T07:24:51.232513Z",
     "start_time": "2024-07-24T07:24:49.971953Z"
    }
   },
   "cell_type": "code",
   "source": "get_sent_word_embeddings(['I am a big foo bar'], model, tokenizer, None)",
   "id": "2de10334b059c0a6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 9.82737169e-02,  1.92254707e-02,  1.50002148e-02,\n",
       "          2.88651371e-03, -5.50648011e-02, -3.68904248e-02,\n",
       "          1.18874013e-01,  4.83325757e-02,  6.01447141e-03,\n",
       "          4.21652161e-02, -3.52831781e-02, -8.36424306e-02,\n",
       "         -3.50537300e-02, -1.95263885e-02,  2.79278532e-02,\n",
       "          3.95715386e-02, -1.28606902e-02,  1.15014147e-02,\n",
       "         -1.06786359e-02, -2.24973243e-02, -1.10274829e-01,\n",
       "          6.65320083e-02,  1.88118499e-02,  1.76326197e-03,\n",
       "         -1.19415283e-01, -1.26929749e-02,  4.31086402e-03,\n",
       "          6.83599897e-03,  8.61172006e-02, -5.21420985e-02,\n",
       "          1.39685320e-02,  7.56450966e-02,  4.12384309e-02,\n",
       "         -1.83217507e-02, -8.99099484e-02, -2.86612986e-03,\n",
       "          4.25359234e-02, -9.02812183e-03,  3.88544612e-02,\n",
       "          4.52078208e-02,  2.26972681e-02, -9.90414154e-03,\n",
       "          3.50649208e-02,  3.34182046e-02, -3.00184805e-02,\n",
       "          1.63097437e-02, -2.29557529e-02,  4.05627266e-02,\n",
       "          7.01322453e-04, -1.12383990e-02,  1.38886692e-03,\n",
       "          7.42447227e-02, -1.00007011e-02,  8.28382149e-02,\n",
       "          1.67382304e-02, -2.78839911e-03, -6.78040907e-02,\n",
       "         -3.44755389e-02,  1.92196947e-02, -3.48526612e-03,\n",
       "          4.29658853e-02,  7.80364648e-02,  4.48678210e-02,\n",
       "          7.02279562e-04,  8.20145458e-02, -2.23266683e-03,\n",
       "          2.70966440e-02,  6.52374923e-02, -6.40463596e-03,\n",
       "          7.98105747e-02,  3.72867398e-02,  4.24769614e-03,\n",
       "         -6.62486106e-02,  7.75601864e-02,  4.17716168e-02,\n",
       "         -7.72168711e-02,  1.01112686e-02,  1.80764236e-02,\n",
       "          7.96335414e-02,  5.86113743e-02, -8.96291211e-02,\n",
       "         -5.06389104e-02, -1.38380798e-03, -6.64793104e-02,\n",
       "         -2.46749097e-03, -3.96805489e-03,  9.97465197e-03,\n",
       "          3.76925990e-02, -4.16932628e-02, -1.92991048e-02,\n",
       "         -9.22479853e-02,  2.64159404e-03, -1.92608777e-02,\n",
       "          3.44808586e-02,  6.14040717e-02, -2.68678479e-02,\n",
       "         -6.77874079e-03, -4.27825637e-02, -4.84716780e-02,\n",
       "          1.23498634e-01,  1.07441723e-01,  4.81154844e-02,\n",
       "          1.32901222e-02,  5.57614379e-02,  4.75342944e-02,\n",
       "         -4.13533412e-02, -2.51554344e-02,  1.12781353e-01,\n",
       "          8.39166865e-02, -4.27664518e-02, -8.53110105e-03,\n",
       "         -3.36282142e-02,  5.26387570e-03, -4.38221265e-03,\n",
       "         -6.17694259e-02, -4.61186729e-02, -8.85777699e-04,\n",
       "          5.69922179e-02, -1.04936454e-02, -3.08804531e-02,\n",
       "         -1.34154903e-02,  1.20151587e-01, -7.96550959e-02,\n",
       "          4.31427471e-02, -9.28648934e-02,  6.83101499e-03,\n",
       "         -4.77832705e-02,  7.37573993e-31, -1.15647636e-01,\n",
       "         -1.96219748e-03,  4.49713655e-02,  6.57176301e-02,\n",
       "          3.82031128e-02, -3.88328284e-02, -7.94089120e-03,\n",
       "          1.69904418e-02, -4.21175472e-02,  7.49837561e-03,\n",
       "          6.03163652e-02, -1.14956191e-02, -7.22538456e-02,\n",
       "          3.63481522e-04,  1.23942465e-01,  6.65539457e-03,\n",
       "         -9.39449668e-03, -3.51815969e-02, -6.88051879e-02,\n",
       "         -3.62145677e-02, -9.02091246e-03, -3.29322778e-02,\n",
       "          4.11546864e-02,  9.85549856e-03,  2.23536845e-02,\n",
       "         -3.80400233e-02,  4.50804830e-02, -3.67927887e-02,\n",
       "         -1.85810570e-02,  3.73182446e-02, -4.90485765e-02,\n",
       "          3.58422683e-03,  3.99393635e-03, -5.49102612e-02,\n",
       "          1.86835579e-03, -1.30513772e-01, -5.72470482e-04,\n",
       "         -1.53122740e-02,  8.82203430e-02, -5.35000255e-03,\n",
       "         -5.20937778e-02, -1.95381418e-02, -4.19064872e-02,\n",
       "         -3.31136249e-02, -1.25052612e-02,  6.04682490e-02,\n",
       "          3.74963395e-02, -4.42484654e-02, -1.41351029e-01,\n",
       "         -2.55801585e-02,  2.71049589e-02,  1.13575859e-03,\n",
       "          5.36750965e-02, -3.54647450e-03, -4.11116285e-03,\n",
       "         -3.15940008e-02,  5.03812321e-02,  5.28129451e-02,\n",
       "          1.40596610e-02,  5.06689027e-02, -5.90926334e-02,\n",
       "          3.59506928e-03, -9.54693928e-03,  8.85809138e-02,\n",
       "         -1.21140681e-01, -6.22852333e-02,  1.87307335e-02,\n",
       "         -5.37946336e-02,  3.97551022e-02,  4.77865934e-02,\n",
       "          7.55114257e-02,  4.20161225e-02, -1.11647854e-02,\n",
       "          1.02780294e-02, -3.20102386e-02,  1.60439219e-02,\n",
       "          7.69499806e-04,  1.26448115e-02, -1.02818094e-01,\n",
       "          7.15114847e-02,  6.69072717e-02,  1.35030067e-02,\n",
       "          8.19593668e-04, -2.77979076e-02,  3.28418501e-02,\n",
       "         -7.58768320e-02,  1.17611839e-02, -8.57803226e-02,\n",
       "          3.76714468e-02,  8.63641966e-03, -1.40528977e-01,\n",
       "          4.78797182e-02,  1.46232359e-02, -7.83592910e-02,\n",
       "         -4.45432961e-02, -2.40803746e-33,  4.16097268e-02,\n",
       "          1.63817834e-02,  3.88807170e-02, -1.83814503e-02,\n",
       "         -1.74494479e-02, -7.57726803e-02,  2.64125522e-02,\n",
       "          1.36527151e-01, -8.80574286e-02,  2.16953997e-02,\n",
       "         -5.91607653e-02,  7.35736871e-03,  2.57605277e-02,\n",
       "         -4.84430864e-02,  8.28052461e-02, -4.76319529e-03,\n",
       "          2.92176567e-02,  1.54949632e-02, -6.97620809e-02,\n",
       "          4.29453030e-02, -3.02874893e-02, -1.90106742e-02,\n",
       "          3.91713157e-02,  9.08220652e-03, -8.29778910e-02,\n",
       "         -3.32784243e-02,  3.67563851e-02,  2.16448791e-02,\n",
       "         -7.48910010e-02, -4.57959548e-02, -1.75534617e-02,\n",
       "         -6.87493710e-03, -8.24583173e-02, -2.85593811e-02,\n",
       "          2.80280020e-02, -6.16848655e-02, -1.80274006e-02,\n",
       "          6.67102030e-03, -9.63613112e-03,  4.07471247e-02,\n",
       "         -3.31874117e-02,  1.95336472e-02,  3.01342569e-02,\n",
       "          6.55118795e-03,  1.40230646e-02, -5.91010377e-02,\n",
       "          7.35435111e-04, -6.91907331e-02,  1.68860238e-02,\n",
       "          2.29332875e-02, -2.79153977e-02, -1.85902771e-02,\n",
       "          4.30558398e-02, -5.91536658e-03,  2.49888953e-02,\n",
       "         -4.40363139e-02, -4.05406859e-03,  4.89950478e-02,\n",
       "         -7.95468017e-02, -1.00296892e-01, -7.41371140e-02,\n",
       "          3.73657160e-02, -1.03026750e-02,  1.95257254e-02,\n",
       "          5.91366477e-02, -5.16587943e-02, -7.89476484e-02,\n",
       "          5.41422106e-02, -7.59624168e-02,  2.44150241e-03,\n",
       "         -2.92918533e-02, -2.55327821e-02, -1.30963743e-01,\n",
       "          1.19338758e-01, -7.03503862e-02, -4.86700125e-02,\n",
       "          1.90375447e-02, -1.99970845e-02,  6.71506301e-02,\n",
       "          6.70660883e-02,  4.54936549e-02, -1.43012824e-02,\n",
       "          1.02839500e-01, -6.14209548e-02, -1.89853832e-02,\n",
       "          6.51976019e-02,  1.32523235e-02,  9.86507982e-02,\n",
       "         -3.75788920e-02,  4.61206846e-02,  1.95370074e-02,\n",
       "          6.10832423e-02, -1.03131264e-01, -5.82588129e-02,\n",
       "          3.38412225e-02, -2.91124235e-33, -6.68746084e-02,\n",
       "         -3.36944242e-03,  2.95035783e-02,  7.70974383e-02,\n",
       "          2.21637655e-02, -2.74540717e-03, -1.06040858e-01,\n",
       "         -1.03981756e-02, -5.25747389e-02,  3.51665579e-02,\n",
       "         -3.08401082e-02,  3.61353308e-02,  1.50847817e-02,\n",
       "          2.48017516e-02, -1.07229371e-02, -5.75151294e-02,\n",
       "         -1.91334728e-02, -6.24795631e-02, -1.17316991e-02,\n",
       "         -2.71596666e-03, -5.23565598e-02,  3.99304517e-02,\n",
       "          3.52488644e-02,  6.13601469e-02, -5.85577786e-02,\n",
       "         -8.76521319e-02,  1.93715934e-02,  2.97862552e-02,\n",
       "         -5.03605604e-03,  3.19483653e-02,  4.72950190e-02,\n",
       "          9.39064100e-02, -1.10841967e-01, -2.47408319e-02,\n",
       "          4.22241539e-02, -5.52880019e-02, -2.10137535e-02,\n",
       "         -2.61025708e-02, -2.85804737e-02,  1.65574308e-02,\n",
       "          1.38622094e-02, -2.02616286e-02,  6.25886172e-02,\n",
       "          4.88931686e-02, -4.48889472e-02,  8.59383866e-03,\n",
       "          1.81503650e-02,  6.42469600e-02,  1.45664327e-02,\n",
       "         -2.28815544e-02,  8.46575722e-02, -1.85921658e-02,\n",
       "          3.11373975e-02,  8.60187039e-02,  2.69187745e-02,\n",
       "          6.18502535e-02, -4.06395495e-02,  3.54668088e-02,\n",
       "         -7.99907744e-02, -2.85273716e-02,  5.10216691e-02,\n",
       "         -2.52831494e-03, -6.20616376e-02, -6.09108061e-02]], dtype=float32),\n",
       " array([[[ 3.55168998e-01,  2.92323828e-02,  1.01136915e-01, ...,\n",
       "          -2.64515188e-02, -4.78748590e-01, -2.42160782e-02],\n",
       "         [ 9.94790614e-01, -7.65286386e-01,  2.22761825e-01, ...,\n",
       "          -2.15924010e-01, -1.14791393e+00, -1.77797949e+00],\n",
       "         [ 8.99299562e-01,  3.04892778e-01,  1.99052259e-01, ...,\n",
       "           1.53585626e-02, -1.07575513e-01, -1.10056889e+00],\n",
       "         ...,\n",
       "         [ 2.86401689e-01,  3.16010684e-01,  1.78617984e-01, ...,\n",
       "          -1.05946243e-01, -6.41173542e-01, -2.44580239e-01],\n",
       "         [ 3.39628875e-01,  3.23380798e-01,  1.77090153e-01, ...,\n",
       "           3.80171463e-04, -8.17297757e-01, -3.15862387e-01],\n",
       "         [ 1.83073953e-01,  2.41282403e-01,  1.34854168e-01, ...,\n",
       "          -7.20330551e-02, -6.22304976e-01, -1.61387235e-01]]],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "    # # load data, filter it, and generate the embeddings\n",
    "    # ann_ids, maps, annotations, authors = get_db_data(cursor=mycursor)\n",
    "    # print(\"Number of levels in db: \", len(ann_ids))\n",
    "    # \n",
    "    # ann_ids, maps, annotations = sort_by_annid(ann_ids, maps, annotations)\n",
    "    # sent_embeddings, word_embeddings = get_sent_word_embeddings(model, tokenizer, annotations, max_len=25)\n",
    "    # data = {\n",
    "    #         'ann_ids' : ann_ids,\n",
    "    #         'images': maps,\n",
    "    #         'labels': annotations,\n",
    "    #         'embeddings': sent_embeddings,\n",
    "    #         'word_embeddings': word_embeddings,\n",
    "    #     }\n",
    "    # np.save('datasets/Map Data/maps_noaug.npy', data, allow_pickle=True)"
   ],
   "id": "21149a39ca7a128"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# do gpt alt label augmentation\n",
    "    ann_ids, maps, annotations, embeddings, authors = gpt_augmentation(ann_ids, maps, annotations, sent_embeddings, authors, model)\n",
    "    print(\"Number of levels before filtering: \", len(ann_ids))\n",
    "\n",
    "    ann_ids_exp = np.array(ann_ids)\n",
    "    maps_exp = np.array(maps)\n",
    "    annotations_exp = np.array(annotations)\n",
    "    embeddings_exp = np.array(embeddings)\n",
    "\n",
    "\n",
    "    export_data(ann_ids_exp, maps_exp, annotations_exp, embeddings_exp, 'datasets/maps_gpt4_aug.npy')"
   ],
   "id": "df7d3536e51258eb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e1f7958f71b30ed9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
